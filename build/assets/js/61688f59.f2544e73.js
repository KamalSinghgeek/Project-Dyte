"use strict";(self.webpackChunkdyte_docs=self.webpackChunkdyte_docs||[]).push([[42410],{85782:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>d,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"capabilities/recording/advanced/interactive-recording","title":"Interactive Recordings with Timed Metadata","description":"Learn how to enable interactive recording with Dyte\'s capabilities. Follow our guide for effective configuration and management.","source":"@site/docs/guides/capabilities/recording/advanced/interactive-recording.mdx","sourceDirName":"capabilities/recording/advanced","slug":"/capabilities/recording/interactive-recording","permalink":"/guides/capabilities/recording/interactive-recording","draft":false,"unlisted":false,"editUrl":"https://github.com/dyte-io/docs/tree/main/docs/guides/capabilities/recording/advanced/interactive-recording.mdx","tags":[],"version":"current","lastUpdatedAt":1731210620000,"sidebarPosition":11,"frontMatter":{"title":"Interactive Recordings with Timed Metadata","sidebar_position":11,"slug":"/capabilities/recording/interactive-recording","description":"Learn how to enable interactive recording with Dyte\'s capabilities. Follow our guide for effective configuration and management."},"sidebar":"tutorialSidebar","previous":{"title":"Disable upload to Dyte\'s bucket","permalink":"/guides/capabilities/recording/configure-dyte-bucket-config"},"next":{"title":"Create Custom Recording App Using Recording SDKs","permalink":"/guides/capabilities/recording/create-record-app-using-sdks"}}');var n=i(74848),r=i(28453);const o={title:"Interactive Recordings with Timed Metadata",sidebar_position:11,slug:"/capabilities/recording/interactive-recording",description:"Learn how to enable interactive recording with Dyte's capabilities. Follow our guide for effective configuration and management."},s=void 0,d={},c=[{value:"What is interactive recording?",id:"what-is-interactive-recording",level:2},{value:"Add interactivity to your Dyte recordings",id:"add-interactivity-to-your-dyte-recordings",level:2}];function l(e){const t={a:"a",admonition:"admonition",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",...(0,r.R)(),...e.components},{Head:i}=t;return i||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.p,{children:["Dyte's interactive recording feature allows you to add timed metadata to your video stream. Timed metadata serves as cue points for clients to display information and trigger time-aligned actions. The metadata is available to clients in the form of ",(0,n.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/ID3",children:"ID3"})," tags on the playback timeline."]}),"\n",(0,n.jsx)(t.h2,{id:"what-is-interactive-recording",children:"What is interactive recording?"}),"\n",(0,n.jsx)(t.p,{children:"Ever wondered how Netflix displays small images on the seek bar or how additional content is shown while watching a cricket match on Hotstar? It's all metadata inserted at a specific time inside the video feed itself, which is called timed metadata."}),"\n",(0,n.jsxs)(t.p,{children:["Timed metadata is metadata with timestamps. It refers to digital markers added to a video file to provide additional context and information at specific points in the content range. These data points can be inserted into a stream programmatically, using the ",(0,n.jsx)(t.code,{children:"interactive_config"})," in the ",(0,n.jsx)(t.a,{href:"/api#/operations/start_recording",children:"Start recording a meeting API"}),"."]}),"\n",(0,n.jsx)(t.p,{children:"Once Dyte processes the stream, the timed metadata gets synchronized with the audio and video frames. This metadata is available to all viewers during playback at the same time relative to the stream. The timecode acts as a cue point and can trigger specific actions based on the data. For example:"}),"\n",(0,n.jsx)(t.p,{children:"These features are made possible through the use of ID3 tags that are embedded in the video segments, making them available in the recorded video."}),"\n",(0,n.jsx)(t.h2,{id:"add-interactivity-to-your-dyte-recordings",children:"Add interactivity to your Dyte recordings"}),"\n",(0,n.jsx)(t.p,{children:"To add interactivity to your Dyte recording, perform the following steps:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsxs)(t.li,{children:["In the ",(0,n.jsx)(t.a,{href:"/api#/operations/start_recording",children:"Start recording a meeting API"}),", pass the ",(0,n.jsx)(t.code,{children:"interactive_config"})," parameter."]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"This parameter enables you to add timed metadata to your recordings, which is made available to clients in HLS format via ID3 tags. The output files are packaged as a tar file."}),"\n",(0,n.jsxs)(t.ol,{start:"2",children:["\n",(0,n.jsxs)(t.li,{children:["In ",(0,n.jsx)(t.a,{href:"/web-core/reference/DyteClient",children:"DyteClient"}),", call the ",(0,n.jsx)(t.code,{children:"broadcastMessage"})," method with the parameters, ",(0,n.jsx)(t.code,{children:"ID3"})," (as a string) and ",(0,n.jsx)(t.code,{children:"yourData"})," (the data you want to send as timed metadata) on the ",(0,n.jsx)(t.a,{href:"/web-core/reference/DyteClient#module_DyteClient+participants",children:"participants"})," object."]}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-ts",children:"client.participants.broadcastMessage(\u201cID3Data\u201d, yourData);\n"})}),"\n",(0,n.jsxs)(t.admonition,{title:"note",type:"info",children:[(0,n.jsxs)(t.p,{children:["This action should only be performed after the recording has been initiated and the system is in the ",(0,n.jsx)(t.code,{children:"RECORDING"})," state. If performed earlier, any associated ID3 tags may be lost."]}),(0,n.jsx)(t.p,{children:"The recommended time to perform this action is after the recording indicator has been displayed for 3 to 4 seconds."})]}),"\n",(0,n.jsxs)(t.ol,{start:"3",children:["\n",(0,n.jsx)(t.li,{children:"To stop sending the data, call the following method. Once you make this call, you will no longer be able to send additional ID3 data."}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-ts",children:"client.participants.broadcastMessage(\u201cID3Data\u201d,\u201dCLOSE_TRANSPORT\u201d)\n"})}),"\n",(0,n.jsx)(t.p,{children:"If you do not pass this parameter, the ID3 metadata stream will automatically be closed when the recording is stopped."}),"\n",(0,n.jsxs)(t.ol,{start:"4",children:["\n",(0,n.jsxs)(t.li,{children:["Once the recording is completed, you can retrieve the tar file that contains video segments and a playlist file. The ",(0,n.jsx)(t.code,{children:"download_url"})," provides the link to the tar file. Below is an example screenshot of a tar file:"]}),"\n"]}),"\n",(0,n.jsx)("img",{src:"/static/guides/tar-format.png",width:"400",height:"300",alt:"interactive-record-tar",className:"interactive-record-tar-file"}),"\n",(0,n.jsx)(t.p,{children:"It's also important to note that the length of each segment depends on the frames of the video. Therefore, each segment may not have the same length, although it is typically close to the specified segment length when the recording was started. By default, the segment length is set to 10 seconds."}),"\n",(0,n.jsxs)(t.ol,{start:"5",children:["\n",(0,n.jsxs)(t.li,{children:["You can play the stream using the ",(0,n.jsx)(t.a,{href:"https://github.com/video-dev/hls.js/",children:(0,n.jsx)(t.code,{children:"hls.js"})}),"."]}),"\n"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-js",children:"const onFragChanged = (_) => {\r\n  // We first try to find the right metadata track.\r\n  // https://developer.mozilla.org/en-US/docs/Web/API/TextTrack\r\n  const textTrackListCount = videoEl.textTracks.length;\r\n  let metaTextTrack;\r\n  for (let trackIndex = 0; trackIndex < textTrackListCount; trackIndex++) {\r\n    const textTrack = videoEl.textTracks[trackIndex];\r\n    if (textTrack.kind !== 'metadata') {\r\n      continue;\r\n    }\r\n    textTrack.mode = 'showing';\r\n    metaTextTrack = textTrack;\r\n    break;\r\n  }\r\n  if (!metaTextTrack) {\r\n    return;\r\n  }\r\n  // Add an oncuechange listener on that track.\r\n  metaTextTrack.oncuechange = (event) => {\r\n    let cue = metaTextTrack.activeCues[metaTextTrack.activeCues.length - 1];\r\n    console.log(cue.value.data);\r\n  };\r\n};\r\n// listen on Hls.Events.FRAG_CHANGED from hls.js\r\nhls.on(Hls.Events.FRAG_CHANGED, onFragChanged);\n"})}),"\n",(0,n.jsxs)(i,{children:[(0,n.jsx)("title",{children:"Interactive Recordings with Timed Metadata Guide"}),(0,n.jsx)("meta",{name:"description",content:"Learn how to enable interactive recording with Dyte's capabilities. Follow our guide for effective configuration and management."})]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},28453:(e,t,i)=>{i.d(t,{R:()=>o,x:()=>s});var a=i(96540);const n={},r=a.createContext(n);function o(e){const t=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),a.createElement(r.Provider,{value:t},e.children)}}}]);