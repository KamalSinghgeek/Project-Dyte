"use strict";(self.webpackChunkdyte_docs=self.webpackChunkdyte_docs||[]).push([[50381],{25125:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>s});const r=JSON.parse('{"id":"pre-call/media-preview","title":"Media Preview","description":"Before joining a meeting, users may want to preview and configure their media devices like camera, microphone, and audio output.","source":"@site/docs/flutter-core/pre-call/1-media-preview.mdx","sourceDirName":"pre-call","slug":"/pre-call/media-preview","permalink":"/flutter-core/pre-call/media-preview","draft":false,"unlisted":false,"editUrl":"https://github.com/dyte-io/docs/tree/main/docs/flutter-core/pre-call/1-media-preview.mdx","tags":[],"version":"current","lastUpdatedAt":1731210620000,"sidebarPosition":1,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Quickstart","permalink":"/flutter-core/"},"next":{"title":"Meeting Metadata","permalink":"/flutter-core/pre-call/meeting-meta"}}');var t=n(74848),d=n(28453);const l={},o="Media Preview",a={},s=[{value:"Properties",id:"properties",level:2},{value:"Methods",id:"methods",level:2},{value:"Toggling Media",id:"toggling-media",level:3},{value:"Changing Media Device",id:"changing-media-device",level:3}];function c(e){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,d.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"media-preview",children:"Media Preview"})}),"\n",(0,t.jsx)(i.p,{children:"Before joining a meeting, users may want to preview and configure their media devices like camera, microphone, and audio output.\r\nThis section provides developers with the tools to prepare the media environment before joining a Dyte meeting."}),"\n",(0,t.jsxs)(i.p,{children:["If you are using our UI Kits, this functionality can be handled by ",(0,t.jsx)(i.code,{children:"DyteSetupScreen"})," or built with ",(0,t.jsx)(i.code,{children:"DyteParticipantTile"})," widget."]}),"\n",(0,t.jsx)(i.h2,{id:"properties",children:"Properties"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"dyteMobileClient.localUser.audioEnabled"}),": A ",(0,t.jsx)("span",{className:"tag-orange",children:"boolean"})," value indicating if the audio currently enabled."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.code,{children:"dyteMobileClient.localUser.videoEnabled"}),": A ",(0,t.jsx)("span",{className:"tag-orange",children:"boolean"})," value indicating if the video currently enabled."]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"methods",children:"Methods"}),"\n",(0,t.jsx)(i.h3,{id:"toggling-media",children:"Toggling Media"}),"\n",(0,t.jsx)(i.p,{children:"The same methods used for controlling media during a meeting are also applicable for pre-call media configuration."}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"1. Mute/Unmute microphone"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-dart",children:"// Mute Audio\r\ndyteMobileClient.localUser.disableAudio()\r\n\r\n// Unmute Audio\r\ndyteMobileClient.localUser.enableAudio()\r\n\n"})}),"\n",(0,t.jsx)(i.mermaid,{value:'flowchart LR\r\n    classDef basic fill:white;\r\n\r\n    eam("enableAudio()") --\x3e success("Gives <code>onAudioUpdate</code> callback to <code>DyteSelfEventsListener</code>")\r\n\r\n    class eam basic;'}),"\n",(0,t.jsx)("br",{}),"\n",(0,t.jsxs)(i.p,{children:["Anytime there is an update in the audio state of the local user, the Core SDK notifies the client through the ",(0,t.jsx)(i.code,{children:"onAudioUpdate"})," callback\r\nfrom ",(0,t.jsx)(i.code,{children:"DyteSelfEventsListener"}),". Here's how you can register the listener:"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-dart",children:"class SelfAudioNotifier extends DyteSelfEventsListener{\r\n    override fun onAudioUpdate(bool audioEnabled) {\r\n    // Show local user's VideoView if video is enabled\r\n    }\r\n}\r\n\r\ndyteMobileClient.addSelfEventsListener(SelfAudioNotifier())\n"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"2. Enable/Disable camera"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-dart",children:"// Disable Video\r\ndyteMobileClient.localUser.disableVideo()\r\n\r\n// Enable Video\r\ndyteMobileClient.localUser.enableVideo()\n"})}),"\n",(0,t.jsx)(i.mermaid,{value:'flowchart LR\r\n    classDef basic fill:white;\r\n\r\n    eam("enableVideo()") --\x3e success("Gives <code>onVideoUpdate</code> callback to <code>DyteSelfEventsListener</code>")\r\n\r\n    class eam basic;'}),"\n",(0,t.jsx)("br",{}),"\n",(0,t.jsxs)(i.p,{children:["Whenever there is an update in the video state of the local user, the Core SDK notifies the client through the ",(0,t.jsx)(i.code,{children:"onVideoUpdate"})," callback\r\nfrom ",(0,t.jsx)(i.code,{children:"DyteSelfEventsListener"}),". Here's how you can register the listener:"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-dart",children:"class SelfVideoNotifier extends DyteSelfEventsListener{\r\n    override fun onVideoUpdate(bool videoEnabled) {\r\n        // Show local user's VideoView if video is enabled\r\n    }\r\n}\r\n\r\ndyteMobileClient.addSelfEventsListener(SelfVideoNotifier());\n"})}),"\n",(0,t.jsx)(i.h3,{id:"changing-media-device",children:"Changing Media Device"}),"\n",(0,t.jsx)(i.p,{children:"Media devices represent the hardware for the camera, microphone, and speaker devices. To get the list of media devices currently\r\navailable, use the following methods:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-dart",children:"// Get all audio devices\r\nfinal audioDevices = dyteMobileClient.localUser.getAudioDevices()\r\n\r\n// Get all video devices\r\nfinal videoDevices = dyteMobileClient.localUser.getVideoDevices()\n"})}),"\n",(0,t.jsx)(i.p,{children:"To get the currently selected media device, use the following methods:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-dart",children:"// Get current audio device being used\r\nfinal currentAudioDevice = dyteMobileClient.localUser.getSelectedAudioDevice()\r\n\r\n// Get current video device being used\r\nfinal currentVideoDevice = dyteMobileClient.localUser.getSelectedVideoDevice()\n"})}),"\n",(0,t.jsx)(i.p,{children:"Use these methods to create a UI that allows users to configure their media devices. When the user selects a device, use the below methods to set the device."}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Set device"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-kotlin",children:"// Set audio device\r\ndyteMobileClient.localUser.setAudioDevice(device)\r\n// eg. device = audioDevices[0]\r\n\r\n// Set video device\r\ndyteMobileClient.localUser.setVideoDevice(device)\r\n// eg. device = videoDevices[0]\n"})})]})}function h(e={}){const{wrapper:i}={...(0,d.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},28453:(e,i,n)=>{n.d(i,{R:()=>l,x:()=>o});var r=n(96540);const t={},d=r.createContext(t);function l(e){const i=r.useContext(d);return r.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),r.createElement(d.Provider,{value:i},e.children)}}}]);