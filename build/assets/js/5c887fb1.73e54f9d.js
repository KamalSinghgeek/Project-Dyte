"use strict";(self.webpackChunkdyte_docs=self.webpackChunkdyte_docs||[]).push([[59875],{28930:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"capabilities/ai/meeting-transcription","title":"Meeting Transcription","description":"Explore meeting transcription capabilities with Dyte\'s AI. Follow our guide to understand and implement transcription features.","source":"@site/docs/guides/capabilities/ai/meeting-transcription.mdx","sourceDirName":"capabilities/ai","slug":"/capabilities/ai/meeting-transcription","permalink":"/guides/capabilities/ai/meeting-transcription","draft":false,"unlisted":false,"editUrl":"https://github.com/dyte-io/docs/tree/main/docs/guides/capabilities/ai/meeting-transcription.mdx","tags":[],"version":"current","lastUpdatedAt":1731210620000,"sidebarPosition":1,"frontMatter":{"sidebar_position":1,"description":"Explore meeting transcription capabilities with Dyte\'s AI. Follow our guide to understand and implement transcription features."},"sidebar":"tutorialSidebar","previous":{"title":"Meeting Summary","permalink":"/guides/capabilities/ai/meeting-summary"},"next":{"title":"Export Chat Messages","permalink":"/guides/capabilities/chat/export-chat-dump"}}');var r=n(74848),s=n(28453);const a={sidebar_position:1,description:"Explore meeting transcription capabilities with Dyte's AI. Follow our guide to understand and implement transcription features."},o="Meeting Transcription",c={},l=[{value:"Control transcriptions for participants using presets",id:"control-transcriptions-for-participants-using-presets",level:2},{value:"Modify Transcription Behavior with AI Config",id:"modify-transcription-behavior-with-ai-config",level:2},{value:"Supported Languages",id:"supported-languages",level:3},{value:"Keywords",id:"keywords",level:3},{value:"Profanity Filter",id:"profanity-filter",level:3},{value:"Example Configuration",id:"example-configuration",level:3},{value:"Consuming transcripts",id:"consuming-transcripts",level:2},{value:"Consuming transcripts in real-time",id:"consuming-transcripts-in-real-time",level:3},{value:"Consume transcript via a post-meeting webhook",id:"consume-transcript-via-a-post-meeting-webhook",level:3},{value:"Fetch the meeting transcript",id:"fetch-the-meeting-transcript",level:2},{value:"Testing transcription",id:"testing-transcription",level:2}];function d(e){const i={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components},{Head:n}=i;return n||function(e,i){throw new Error("Expected "+(i?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"meeting-transcription",children:"Meeting Transcription"})}),"\n",(0,r.jsx)(i.admonition,{title:"beta",type:"info",children:(0,r.jsxs)(i.p,{children:["The meeting transcription feature is currently in beta, which means it is still being tested and evaluated, and may undergo some change. This feature is not accessible to the public at the moment and will be activated solely upon request, subject to our team's assessment of your usage and needs. If you wish to have this feature enabled for your organization, please ",(0,r.jsx)(i.a,{href:"https://dyte.io/contact",children:"get in touch with us"}),"."]})}),"\n",(0,r.jsx)(i.p,{children:"Dyte's meeting transcription allows you to transcribe your Dyte meetings in real-time, making it easy to capture important discussions and refer back to them later.\r\nThis guide will walk you through how to use this feature effectively."}),"\n",(0,r.jsx)(i.h2,{id:"control-transcriptions-for-participants-using-presets",children:"Control transcriptions for participants using presets"}),"\n",(0,r.jsxs)(i.p,{children:["You can control whether or not a participant's audio will be transcribe with the help of the ",(0,r.jsx)(i.code,{children:"transcription_enabled"})," flag in the participant's preset.\r\nAll participants with the ",(0,r.jsx)(i.code,{children:"transcription_enabled"})," turned on in their preset will be able to generate transcripts in real-time in a Dyte meeting."]}),"\n",(0,r.jsxs)(i.p,{children:["You can create a new preset on our ",(0,r.jsx)(i.a,{href:"https://dev.dyte.io/presets",children:"Developer Portal"}),", or using our ",(0,r.jsx)(i.a,{href:"/api#/operations/post-presets",children:"REST API"}),"."]}),"\n",(0,r.jsx)(i.h2,{id:"modify-transcription-behavior-with-ai-config",children:"Modify Transcription Behavior with AI Config"}),"\n",(0,r.jsxs)(i.p,{children:["You can control transcription behavior through a configurable AI setup. When creating a meeting using the ",(0,r.jsx)(i.a,{href:"/api#/operations/create_meeting",children:"REST API"}),", you can pass an AI configuration for transcriptions. This allows for greater control over the transcription process."]}),"\n",(0,r.jsx)(i.h3,{id:"supported-languages",children:"Supported Languages"}),"\n",(0,r.jsx)(i.p,{children:"You can specify the language for transcription to ensure accurate and relevant results. The following languages are supported:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"English (United States):"})," ",(0,r.jsx)(i.code,{children:"en-US"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"English (India):"})," ",(0,r.jsx)(i.code,{children:"en-IN"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"German:"})," ",(0,r.jsx)(i.code,{children:"de"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"Hindi:"})," ",(0,r.jsx)(i.code,{children:"hi"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"Swedish:"})," ",(0,r.jsx)(i.code,{children:"sv"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"Russian:"})," ",(0,r.jsx)(i.code,{children:"ru"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"Polish:"})," ",(0,r.jsx)(i.code,{children:"pl"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"Greek:"})," ",(0,r.jsx)(i.code,{children:"el"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"French:"})," ",(0,r.jsx)(i.code,{children:"fr"})]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.em,{children:"Dutch:"})," ",(0,r.jsx)(i.code,{children:"nl"})]}),"\n"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-json",metastring:"lines",children:'"language": "en-US"\n'})}),"\n",(0,r.jsx)(i.h3,{id:"keywords",children:"Keywords"}),"\n",(0,r.jsx)(i.p,{children:"Keywords can be added to help the transcription engine accurately detect and transcribe specific terms, such as names, technical jargon, or other context-specific words. This is particularly useful in meetings where certain terms are frequently used and need to be recognized correctly."}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-json",metastring:"lines",children:'"keywords": ["Dyte", "Mary", "Sue"]\n'})}),"\n",(0,r.jsx)(i.h3,{id:"profanity-filter",children:"Profanity Filter"}),"\n",(0,r.jsx)(i.p,{children:"You can enable or disable the profanity filter based on your needs. This feature ensures that any offensive language is either included or excluded from the transcriptions, depending on your preference."}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-json",metastring:"lines",children:'"profanity_filter": false\n'})}),"\n",(0,r.jsx)(i.p,{children:"By utilizing these new features, you can customize the transcription experience to better suit your needs."}),"\n",(0,r.jsx)(i.h3,{id:"example-configuration",children:"Example Configuration"}),"\n",(0,r.jsxs)(i.p,{children:["Here is an example of how to pass the AI configuration in the ",(0,r.jsx)(i.a,{href:"/api#/operations/create_meeting",children:"meeting creation API"}),":"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-json",children:'{\r\n  "title": "Meeting Transcriptions",\r\n  "ai_config": {\r\n    "transcription": {\r\n      "keywords": ["Dyte"],\r\n      "language": "en-US",\r\n      "profanity_filter": false\r\n    }\r\n  }\r\n}\r\n\n'})}),"\n",(0,r.jsx)(i.h2,{id:"consuming-transcripts",children:"Consuming transcripts"}),"\n",(0,r.jsx)(i.p,{children:"There are 3 ways in which these transcripts can be consumed."}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsx)(i.li,{children:"Client core SDK: The transcripts can be consumed on the client-side using the Dyte SDK that's suitable for your platform. These transcripts are generated on the server in real-time."}),"\n",(0,r.jsxs)(i.li,{children:["Webhooks: The meeting transcript can be consumed via a ",(0,r.jsx)(i.a,{href:"#consume-transcript-via-a-post-meeting-webhook",children:"webhook after the meeting ends"}),"."]}),"\n",(0,r.jsxs)(i.li,{children:["REST API: The meeting transcript can also be fetched via the ",(0,r.jsx)(i.a,{href:"/api#/operations/GetSessionTranscript",children:"rest API"}),"."]}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"consuming-transcripts-in-real-time",children:"Consuming transcripts in real-time"}),"\n",(0,r.jsxs)(i.p,{children:["For consuming transcripts in real-time on the client SDK of your choice, you just need to ensure that the ",(0,r.jsx)(i.code,{children:"transcription_enabled"})," flag is enabled in the preset.\r\nTranscripts for all the participants having this flag set will be broadcasted in the meeting."]}),"\n",(0,r.jsxs)(i.p,{children:["You can use the ",(0,r.jsx)(i.code,{children:"meeting.ai"})," object to access the transcripts."]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-ts",children:"console.log(meeting.ai.transcripts);\n"})}),"\n",(0,r.jsxs)(i.p,{children:["The transcripts are also emitted by the ",(0,r.jsx)(i.code,{children:"meeting.ai"})," object, so a listener can be attached to it."]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-ts",children:"meeting.ai.on('transcript', (transcriptData) => {\r\n  console.log('Transcript:', transcriptData);\r\n});\n"})}),"\n",(0,r.jsxs)(i.p,{children:["As participants speak during the meeting, you'll receive partial transcripts, giving you real-time feedback even before they finish their sentences. The ",(0,r.jsx)(i.code,{children:"isPartialTranscript"})," flag in the transcript data shows whether the transcript is partial or final."]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-json",children:'{\r\n  "id": "1a2b3c4d-5678-90ab-cdef-1234567890ab",\r\n  "name": "Alice",\r\n  "peerId": "4f5g6h7i-8j9k-0lmn-opqr-1234567890st",\r\n  "userId": "uvwxyz-1234-5678-90ab-cdefghijklmn",\r\n  "customParticipantId": "abc123xyz",\r\n  "transcript": "Hello?",\r\n  "isPartialTranscript": true,\r\n  "date": "Wed Aug 07 2024 10:15:30 GMT+0530 (India Standard Time)"\r\n}\n'})}),"\n",(0,r.jsxs)(i.p,{children:["In the example above, ",(0,r.jsx)(i.code,{children:"isPartialTranscript"})," is true, indicating the transcript is still in progress. Once the participant finishes speaking, the final transcript will be sent with ",(0,r.jsx)(i.code,{children:"isPartialTranscript"})," set to false. This helps you distinguish between ongoing speech and completed transcriptions, making the transcription process more dynamic and responsive."]}),"\n",(0,r.jsx)(i.h3,{id:"consume-transcript-via-a-post-meeting-webhook",children:"Consume transcript via a post-meeting webhook"}),"\n",(0,r.jsxs)(i.p,{children:["You can configure a webhook with the ",(0,r.jsx)(i.code,{children:"meeting.transcript"})," event enabled to receive the meeting transcript after the meeting has ended.\r\nYou can do this either on our ",(0,r.jsx)(i.a,{href:"https://dev.dyte.io/webhooks",children:"Developer Portal"}),", or using a ",(0,r.jsx)(i.a,{href:"/api#/operations/addWebhook",children:"REST API"}),"."]}),"\n",(0,r.jsxs)(i.p,{children:["You can see the webhook format ",(0,r.jsx)(i.a,{href:"/guides/capabilities/webhooks/webhook-events#meetingtranscript",children:"here"}),"."]}),"\n",(0,r.jsx)(i.h2,{id:"fetch-the-meeting-transcript",children:"Fetch the meeting transcript"}),"\n",(0,r.jsxs)(i.p,{children:["You do not need to rely on the webhook to get the transcript for a meeting. Dyte provides a ",(0,r.jsx)(i.a,{href:"/api#/operations/GetSessionTranscript",children:"REST API"})," using which you can obtain the transcripts for a particular session.\r\nYou can use this API to get the transcript for a meeting at a later time. Dyte stores the transcript of a meeting for 7 days since the start of the meeting."]}),"\n",(0,r.jsx)(i.p,{children:"The transcript is received in the form of a CSV. Here is the format of the said CSV:"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-csv",children:"Timestamp, Participant ID, User ID, Custom Participant ID, Participant Name, Transcript\n"})}),"\n",(0,r.jsx)(i.p,{children:"The following is a description of all the fields specified in the above CSV."}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsx)(i.li,{children:"Timestamp: An ISO 8601 format string indicating the time of utterance (or the time of speech)."}),"\n",(0,r.jsx)(i.li,{children:'Participant ID: An identifier for individual peers in the meeting. For instance, if the participant joins the meeting twice, both the "peers" will have the same User ID but different Participant IDs.'}),"\n",(0,r.jsxs)(i.li,{children:["User ID: An identifier for a participant in the meeting, as returned by the ",(0,r.jsx)(i.a,{href:"/api#/operations/add_participant#response-body",children:"add participant API call"}),"."]}),"\n",(0,r.jsxs)(i.li,{children:["Custom Participant ID: An identifier that you can specify to identify a user. This can be sent in the request body of the ",(0,r.jsx)(i.a,{href:"/api#/operations/add_participant#request-body",children:"add participant API call"}),"."]}),"\n",(0,r.jsx)(i.li,{children:"Participant Name: The display name of the user."}),"\n",(0,r.jsx)(i.li,{children:"Transcript: The transcribed utterance."}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"testing-transcription",children:"Testing transcription"}),"\n",(0,r.jsx)(i.p,{children:"Once you have configured a preset and a webhook according to the instructions above, you can proceed to test whether meeting transcription is working for your organization.\r\nTo test if meeting transcription has been configured for your organization, perform the following steps."}),"\n",(0,r.jsxs)(i.ol,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"/api#/operations/create_meeting",children:"Create a meeting"}),"."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.a,{href:"/api#/operations/add_participant",children:"Add a participant"})," to the meeting. Make sure that the preset you use was configured according to this guide."]}),"\n",(0,r.jsxs)(i.li,{children:["Join the meeting with the ",(0,r.jsx)(i.code,{children:"authToken"})," you just obtained. As you unmute and speak, your speech should be getting transcribed in real-time for all the participants in the meeting."]}),"\n",(0,r.jsxs)(i.li,{children:["Once the meeting ends, you will be getting a webhook with the event ",(0,r.jsx)(i.code,{children:"meeting.transcript"}),". The body of this webhook will consist of the entire meeting transcript."]}),"\n"]}),"\n",(0,r.jsxs)(n,{children:[(0,r.jsx)("title",{children:"Meeting Transcription Guide"}),(0,r.jsx)("meta",{name:"description",content:"Explore meeting transcription capabilities with Dyte's AI. Follow our guide to understand and implement transcription features."})]})]})}function h(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,i,n)=>{n.d(i,{R:()=>a,x:()=>o});var t=n(96540);const r={},s=t.createContext(r);function a(e){const i=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(s.Provider,{value:i},e.children)}}}]);